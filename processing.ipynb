{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runs on cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    runs_on_gpu = True\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    runs_on_gpu = False\n",
    "print(f\"Runs on {device.type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20100 entries, 0 to 20099\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   directions   20100 non-null  object        \n",
      " 1   fat          15901 non-null  float64       \n",
      " 2   date         20100 non-null  datetime64[ns]\n",
      " 3   categories   20100 non-null  object        \n",
      " 4   calories     15969 non-null  float64       \n",
      " 5   desc         20100 non-null  object        \n",
      " 6   protein      15922 non-null  float64       \n",
      " 7   rating       20100 non-null  float64       \n",
      " 8   title        20100 non-null  object        \n",
      " 9   ingredients  20100 non-null  object        \n",
      " 10  sodium       15967 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(5), object(5)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json('preprocessed_recipes.json')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directions</th>\n",
       "      <th>fat</th>\n",
       "      <th>date</th>\n",
       "      <th>categories</th>\n",
       "      <th>calories</th>\n",
       "      <th>desc</th>\n",
       "      <th>protein</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>sodium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Place the stock, lentils, celery, carrot, t...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2006-09-01 04:00:00</td>\n",
       "      <td>[Sandwich, Bean, Fruit, Tomato, turkey, Vegeta...</td>\n",
       "      <td>426.0</td>\n",
       "      <td></td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.500</td>\n",
       "      <td>Lentil, Apple, and Turkey Wrap</td>\n",
       "      <td>[4 cups low-sodium vegetable or chicken stock,...</td>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine first 9 ingredients in heavy medium sa...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2004-08-20 04:00:00</td>\n",
       "      <td>[Food Processor, Onion, Pork, Bake, Bastille D...</td>\n",
       "      <td>403.0</td>\n",
       "      <td>This uses the same ingredients found in boudin...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.375</td>\n",
       "      <td>Boudin Blanc Terrine with Red Onion Confit</td>\n",
       "      <td>[1 1/2 cups whipping cream, 2 medium onions, c...</td>\n",
       "      <td>1439.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In a large heavy saucepan cook diced fennel an...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2004-08-20 04:00:00</td>\n",
       "      <td>[Soup/Stew, Dairy, Potato, Vegetable, Fennel, ...</td>\n",
       "      <td>165.0</td>\n",
       "      <td></td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.750</td>\n",
       "      <td>Potato and Fennel Soup Hodge</td>\n",
       "      <td>[1 fennel bulb (sometimes called anise), stalk...</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heat oil in heavy large skillet over medium-hi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-03-27 04:00:00</td>\n",
       "      <td>[Fish, Olive, Tomato, Sauté, Low Fat, Low Cal,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sicilian-style tomato sauce has tons of Me...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000</td>\n",
       "      <td>Mahi-Mahi in Tomato Olive Sauce</td>\n",
       "      <td>[2 tablespoons extra-virgin olive oil, 1 cup c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Preheat oven to 350°F. Lightly grease 8x8x2-in...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2004-08-20 04:00:00</td>\n",
       "      <td>[Cheese, Dairy, Pasta, Vegetable, Side, Bake, ...</td>\n",
       "      <td>547.0</td>\n",
       "      <td></td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.125</td>\n",
       "      <td>Spinach Noodle Casserole</td>\n",
       "      <td>[1 12-ounce package frozen spinach soufflé, th...</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          directions   fat  \\\n",
       "0  1. Place the stock, lentils, celery, carrot, t...   7.0   \n",
       "1  Combine first 9 ingredients in heavy medium sa...  23.0   \n",
       "2  In a large heavy saucepan cook diced fennel an...   7.0   \n",
       "3  Heat oil in heavy large skillet over medium-hi...   NaN   \n",
       "4  Preheat oven to 350°F. Lightly grease 8x8x2-in...  32.0   \n",
       "\n",
       "                 date                                         categories  \\\n",
       "0 2006-09-01 04:00:00  [Sandwich, Bean, Fruit, Tomato, turkey, Vegeta...   \n",
       "1 2004-08-20 04:00:00  [Food Processor, Onion, Pork, Bake, Bastille D...   \n",
       "2 2004-08-20 04:00:00  [Soup/Stew, Dairy, Potato, Vegetable, Fennel, ...   \n",
       "3 2009-03-27 04:00:00  [Fish, Olive, Tomato, Sauté, Low Fat, Low Cal,...   \n",
       "4 2004-08-20 04:00:00  [Cheese, Dairy, Pasta, Vegetable, Side, Bake, ...   \n",
       "\n",
       "   calories                                               desc  protein  \\\n",
       "0     426.0                                                        30.0   \n",
       "1     403.0  This uses the same ingredients found in boudin...     18.0   \n",
       "2     165.0                                                         6.0   \n",
       "3       NaN  The Sicilian-style tomato sauce has tons of Me...      NaN   \n",
       "4     547.0                                                        20.0   \n",
       "\n",
       "   rating                                        title  \\\n",
       "0   2.500              Lentil, Apple, and Turkey Wrap    \n",
       "1   4.375  Boudin Blanc Terrine with Red Onion Confit    \n",
       "2   3.750                Potato and Fennel Soup Hodge    \n",
       "3   5.000             Mahi-Mahi in Tomato Olive Sauce    \n",
       "4   3.125                    Spinach Noodle Casserole    \n",
       "\n",
       "                                         ingredients  sodium  \n",
       "0  [4 cups low-sodium vegetable or chicken stock,...   559.0  \n",
       "1  [1 1/2 cups whipping cream, 2 medium onions, c...  1439.0  \n",
       "2  [1 fennel bulb (sometimes called anise), stalk...   165.0  \n",
       "3  [2 tablespoons extra-virgin olive oil, 1 cup c...     NaN  \n",
       "4  [1 12-ounce package frozen spinach soufflé, th...   452.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mandatory_columns = ['directions', 'date', 'categories', 'title', 'ingredients']\n",
    "optional_columns = ['fat', 'calories', 'desc', 'protein', 'sodium']\n",
    "numerical_columns = ['fat', 'calories', 'protein', 'sodium']\n",
    "textual_columns = ['title', 'directions', 'desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='rating'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratings = data['rating']\n",
    "data.drop(columns=['rating'])\n",
    "rating_value_counts = ratings.value_counts() / len(ratings)\n",
    "sns.barplot(x=rating_value_counts.index, y=rating_value_counts.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Basic Project\n",
    "The basic project will consist of solving a regression task, comparing the performance obtained using different vectorizations of the documents and at least two different machine learning strategies, as described below. \n",
    "\n",
    "You should use the information in the directions and/or desc variables for all steps of the project, possibly combining this information with metadata from other variables. You should use appropriate metrics for evaluating this task. The performance of the different methods should be estimated using a validation methodology, which you should also explain in the documentation. You should provide a description of the methodology used and analyze the performance obtained according to the input variables.\n",
    "Keep in mind that the goal is to describe the work carried out and critically analyze the results obtained. Support this with graphs or other representations you consider appropriate. There is no need to describe the algorithms used, but you should explain how you tuned their parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rating: 3.7130597014925373 and MSE: 1.8039448048934432\n"
     ]
    }
   ],
   "source": [
    "mean_rating = np.mean(data['rating'])\n",
    "baseline_mse = np.mean((data['rating'] - mean_rating)**2)\n",
    "print(f\"Mean rating: {mean_rating} and MSE: {baseline_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.242109763681592\n"
     ]
    }
   ],
   "source": [
    "most_used_rating = 4.375\n",
    "mse = np.mean((data['rating'] - most_used_rating)**2)\n",
    "print(f\"MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4\n",
    "Training and evaluation of regression models using at least the following two machine learning strategies:\n",
    "- Neural networks using PyTorch for implementation.\n",
    "- At least one other technique implemented in the Scikit-learn library\n",
    "(e.g., K-NN, SVM, Random Forest, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks using PyTorch for implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, int(input_size/2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(int(input_size/2), 256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.relu3(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = pd.read_hdf('local_store.h5', key='tfidf').to_numpy()\n",
    "#embeddings = pd.read_hdf('local_store.h5', key='word2vec').to_numpy()\n",
    "embeddings = np.load(\"context_embedding.npy\")\n",
    "embeddings = embeddings.reshape(embeddings.shape[0], -1)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, ratings.to_numpy(), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Matrix:  torch.Size([16080, 2304]) torch.Size([16080, 1])\n",
      "Test Matrix:  (4020, 2304)\n",
      "input_size:  2304\n",
      "Epoch [1/100], Loss: 15.8165\n",
      "Epoch [11/100], Loss: 3.0850\n",
      "Epoch [21/100], Loss: 2.0704\n",
      "Epoch [31/100], Loss: 1.6803\n",
      "Epoch [41/100], Loss: 1.6408\n",
      "Epoch [51/100], Loss: 1.6253\n",
      "Epoch [61/100], Loss: 1.6041\n",
      "Epoch [71/100], Loss: 1.5852\n",
      "Epoch [81/100], Loss: 1.5714\n",
      "Epoch [91/100], Loss: 1.5545\n",
      "Epoch [100/100], Loss: 1.5387\n",
      "Test Loss: 1.6321\n",
      "Compared to baseline mse: 111%\n"
     ]
    }
   ],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "y_train_tensor = y_train_tensor.unsqueeze(1)\n",
    "\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "y_test_tensor = y_test_tensor.unsqueeze(1)\n",
    "\n",
    "print('Training Matrix: ', X_train_tensor.shape, y_train_tensor.shape)\n",
    "print('Test Matrix: ', X_test.shape)\n",
    " \n",
    "input_size = X_train.shape[1]\n",
    "print('input_size: ', input_size)\n",
    "\n",
    "model = RegressionModel(input_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(X_train_tensor)\n",
    "    \n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch % 10 == 0):\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_outputs = torch.round(model(X_test_tensor))\n",
    "    \n",
    "test_loss = criterion(test_outputs, y_test_tensor)\n",
    "print(f'Test Loss: {test_loss.item():.4f}')\n",
    "print(f\"Compared to baseline mse: {baseline_mse / test_loss * 100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - At least one other technique implemented in the Scikit-learn library\n",
    "(e.g., K-NN, SVM, Random Forest, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate(model, X, y):\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_score = scores.mean() * -1\n",
    "    print(f'Mean MSE: {mean_score} - mean error: {mean_score**0.5}')\n",
    "    print(f\"Compared to baseline mse: {baseline_mse / mean_score * 100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model RandomForestRegressor() with numerical_columns\n",
      "Mean MSE: 1.6266807420393576 - mean error: 1.2754139492883703\n",
      "Compared to baseline mse: 111%\n",
      "Training model SVR() with numerical_columns\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 196, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 2961, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1370, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1107, in check_array\n    _assert_all_finite(\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nSVR does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, X \u001b[38;5;129;01min\u001b[39;00m data_configs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m     \u001b[43mfit_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m, in \u001b[0;36mfit_and_evaluate\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_and_evaluate\u001b[39m(model, X, y):\n\u001b[0;32m----> 2\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneg_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     mean_score \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - mean error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_score\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:684\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    682\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 684\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:431\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    411\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    412\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    413\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    429\u001b[0m )\n\u001b[0;32m--> 431\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    516\u001b[0m     )\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 196, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 2961, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1370, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1107, in check_array\n    _assert_all_finite(\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/benedikt.mehl/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nSVR does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "def get_context_embeddings():\n",
    "    embeddings = np.load(\"context_embedding.npy\")\n",
    "    embeddings = embeddings.reshape(embeddings.shape[0], -1)\n",
    "    return embeddings\n",
    "\n",
    "data_configs = {\n",
    "    'numerical_columns': data[numerical_columns],\n",
    "    #'tfidf': pd.read_hdf('local_store.h5', key='tfidf').to_numpy(),\n",
    "    #'word2vec': pd.read_hdf('local_store.h5', key='word2vec').to_numpy(),\n",
    "    #'context_embedding': get_context_embeddings(),\n",
    "}\n",
    "\n",
    "models = [RandomForestRegressor(), SVR()] \n",
    "for model in models:\n",
    "    for key, X in data_configs.items():\n",
    "        print(f\"Training model {model} with {key}\")\n",
    "        fit_and_evaluate(model, X, ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5\n",
    "Comparison of the results obtained in step 3 with fine-tuning a pre-trained model from Hugging Face. In this step, you are asked to use a transformer model with a regression head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['directions'].tolist()\n",
    "y = ratings.to_numpy(dtype='float32')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/3015 [05:41<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 13.6354, 'grad_norm': 110.56185913085938, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/3015 [05:44<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 12.4936, 'grad_norm': 127.78746032714844, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/3015 [05:48<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.6723, 'grad_norm': 95.80782318115234, 'learning_rate': 3e-06, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/3015 [05:51<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.7736, 'grad_norm': 114.6506118774414, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/3015 [05:55<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.0099, 'grad_norm': 84.49993896484375, 'learning_rate': 5e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Start fine-tuning\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     46\u001b[0m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/transformers/trainer.py:2164\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2165\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2169\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/transformers/trainer.py:2575\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2571\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[1;32m   2573\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_pre_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2579\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/accelerate/optimizer.py:178\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:137\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    136\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/torch/optim/adamw.py:220\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    207\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    209\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    210\u001b[0m         group,\n\u001b[1;32m    211\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m         state_steps,\n\u001b[1;32m    218\u001b[0m     )\n\u001b[0;32m--> 220\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/torch/optim/adamw.py:782\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    780\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 782\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-MaibornWolffGmbH/Privat/Studium/Master_V/DataProcessing/Code/lib/python3.12/site-packages/torch/optim/adamw.py:375\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    372\u001b[0m param\u001b[38;5;241m.\u001b[39mmul_(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m weight_decay)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = Dataset(train_encodings, y_train)\n",
    "test_dataset = Dataset(test_encodings, y_test)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results', # Output directory\n",
    "    num_train_epochs=3, # Number of epochs\n",
    "    per_device_train_batch_size=16, # Training batch size\n",
    "    per_device_eval_batch_size=64, # Evaluation batch size\n",
    "    warmup_steps=500, # Warmup steps\n",
    "    weight_decay=0.01, # Weight decay\n",
    "    logging_dir='./logs', # Logging directory\n",
    "    logging_steps=10,\n",
    "    report_to=[],\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, # Pre-trained model\n",
    "    args=training_args, # Training arguments\n",
    "    train_dataset=train_dataset, # Training data\n",
    "    eval_dataset=test_dataset # Evaluation data\n",
    ")\n",
    "\n",
    "print(\"Start training\")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./fine-tuned-bert')\n",
    "tokenizer.save_pretrained('./fine-tuned-bert')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
